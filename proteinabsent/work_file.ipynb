{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import zip_longest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_protein_id(element, treshold):\n",
    "    result = {}\n",
    "    empty_result = {'-': None}\n",
    "    for item in element:\n",
    "        try:\n",
    "            e_value_1 = float(item[3])\n",
    "        except ValueError:\n",
    "            return empty_result\n",
    "        \n",
    "        if e_value_1 <= treshold:\n",
    "            local_key = item[2]\n",
    "            if local_key == '-':\n",
    "                local_key = f'loc_tag={item[1]}'\n",
    "            \n",
    "            if local_key not in result:\n",
    "                result[local_key] = e_value_1\n",
    "            else:\n",
    "                if e_value_1 <= result[local_key]:\n",
    "                    result[local_key] = e_value_1\n",
    "                    \n",
    "    if len(result) == 0:\n",
    "        return empty_result\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чтение файлов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('seq_database.fasta', 'r') as file:\n",
    "    content = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Term_hmmsearch.out', 'r') as file:\n",
    "    term_hmmsearch = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('TMP_hmmsearch.out', 'r') as file:\n",
    "    tmp_hmmsearch = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('MCP_hmmsearch.out', 'r') as file:\n",
    "    mcp_hmmsearch = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ParA_hmmsearch.out', 'r') as file:\n",
    "    para_hmmsearch = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ParM_hmmsearch.out', 'r') as file:\n",
    "    parm_hmmsearch = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('XerC_hmmsearch.out', 'r') as file:\n",
    "    xerc_hmmsearch = file.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Поиск вхождений плазмид в группы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prot_names = []\n",
    "for item in content:\n",
    "    try:\n",
    "        prot_name = item.split('_prot_')[0].split('|')[1]\n",
    "        if prot_name not in prot_names:\n",
    "            prot_names.append(prot_name)\n",
    "        else:\n",
    "            continue\n",
    "    except IndexError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_hmmsearch_dict = dict.fromkeys(prot_names, 0)\n",
    "tmp_hmmsearch_dict = dict.fromkeys(prot_names, 0)\n",
    "mcp_hmmsearch_dict = dict.fromkeys(prot_names, 0)\n",
    "para_hmmsearch_dict = dict.fromkeys(prot_names, 0)\n",
    "parm_hmmsearch_dict = dict.fromkeys(prot_names, 0)\n",
    "xerc_hmmsearch_dict = dict.fromkeys(prot_names, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loop_content = (\n",
    "    (term_hmmsearch, term_hmmsearch_dict),\n",
    "    (tmp_hmmsearch, tmp_hmmsearch_dict),\n",
    "    (mcp_hmmsearch, mcp_hmmsearch_dict),\n",
    "    (para_hmmsearch, para_hmmsearch_dict),\n",
    "    (parm_hmmsearch, parm_hmmsearch_dict),\n",
    "    (xerc_hmmsearch, xerc_hmmsearch_dict)\n",
    "    \n",
    ")\n",
    "\n",
    "for prot_name in prot_names:\n",
    "    for lines, dict_prot in loop_content:\n",
    "        for line in lines:\n",
    "            try:\n",
    "                prot_name_line = line.split('_prot_')[0].split('|')[1]\n",
    "            except IndexError:\n",
    "                continue\n",
    "            if prot_name == prot_name_line:\n",
    "                dict_prot[prot_name] +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('resultsmatch.out', 'w') as file:\n",
    "    file.write(\n",
    "        f'Plasmids\\tTerm\\tTMP\\tMCP\\tParA\\tParM\\tXerC\\t'\n",
    "        f'TeTmM\\tTeTmMPa\\tTeTmMPm\\tTeTmMPaPm\\tTeTmMX\\t'\n",
    "        f'TeTmMPaX\\tTeTmMPmX\\tTeTmMPaPmX\\tTeTmPa\\tTeMPa\\n'\n",
    "    )\n",
    "    \n",
    "    for prot_name in prot_names:\n",
    "        file.write(f'{prot_name}\\t')\n",
    "        file.write(f'{term_hmmsearch_dict[prot_name]}\\t')\n",
    "        file.write(f'{tmp_hmmsearch_dict[prot_name]}\\t')\n",
    "        file.write(f'{mcp_hmmsearch_dict[prot_name]}\\t')\n",
    "        file.write(f'{para_hmmsearch_dict[prot_name]}\\t')\n",
    "        file.write(f'{parm_hmmsearch_dict[prot_name]}\\t')\n",
    "        file.write(f'{xerc_hmmsearch_dict[prot_name]}\\t')\n",
    "        \n",
    "        # TeTmM\n",
    "        if (term_hmmsearch_dict[prot_name] != 0\n",
    "            and tmp_hmmsearch_dict[prot_name] != 0\n",
    "            and mcp_hmmsearch_dict[prot_name] != 0\n",
    "           ):\n",
    "            file.write(f'+\\t')\n",
    "        else:\n",
    "            file.write(f' \\t')\n",
    "        \n",
    "        #TeTmMPa\n",
    "        if (term_hmmsearch_dict[prot_name] != 0\n",
    "            and tmp_hmmsearch_dict[prot_name] != 0\n",
    "            and mcp_hmmsearch_dict[prot_name] != 0\n",
    "            and para_hmmsearch_dict[prot_name] != 0\n",
    "           ):\n",
    "            file.write(f'+\\t')\n",
    "        else:\n",
    "            file.write(f' \\t')\n",
    "            \n",
    "        #TeTmMPm\n",
    "        if (term_hmmsearch_dict[prot_name] != 0\n",
    "            and tmp_hmmsearch_dict[prot_name] != 0\n",
    "            and mcp_hmmsearch_dict[prot_name] != 0\n",
    "            and parm_hmmsearch_dict[prot_name] != 0\n",
    "           ):\n",
    "            file.write(f'+\\t')\n",
    "        else:\n",
    "            file.write(f' \\t')\n",
    "        \n",
    "        #TeTmMPaPm\n",
    "        if (term_hmmsearch_dict[prot_name] != 0\n",
    "            and tmp_hmmsearch_dict[prot_name] != 0\n",
    "            and mcp_hmmsearch_dict[prot_name] != 0\n",
    "            and para_hmmsearch_dict[prot_name] != 0\n",
    "            and parm_hmmsearch_dict[prot_name] != 0\n",
    "           ):\n",
    "            file.write(f'+\\t')\n",
    "        else:\n",
    "            file.write(f' \\t')\n",
    "        \n",
    "        #TeTmMX\n",
    "        if (term_hmmsearch_dict[prot_name] != 0\n",
    "            and tmp_hmmsearch_dict[prot_name] != 0\n",
    "            and mcp_hmmsearch_dict[prot_name] != 0\n",
    "            and xerc_hmmsearch_dict[prot_name] != 0\n",
    "           ):\n",
    "            file.write(f'+\\t')\n",
    "        else:\n",
    "            file.write(f' \\t')\n",
    "            \n",
    "        #TeTmMPaX\n",
    "        if (term_hmmsearch_dict[prot_name] != 0\n",
    "            and tmp_hmmsearch_dict[prot_name] != 0\n",
    "            and mcp_hmmsearch_dict[prot_name] != 0\n",
    "            and para_hmmsearch_dict[prot_name] != 0\n",
    "            and xerc_hmmsearch_dict[prot_name] != 0\n",
    "           ):\n",
    "            file.write(f'+\\t')\n",
    "        else:\n",
    "            file.write(f' \\t')\n",
    "            \n",
    "        #TeTmMPmX\n",
    "        if (term_hmmsearch_dict[prot_name] != 0\n",
    "            and tmp_hmmsearch_dict[prot_name] != 0\n",
    "            and mcp_hmmsearch_dict[prot_name] != 0\n",
    "            and parm_hmmsearch_dict[prot_name] != 0\n",
    "            and xerc_hmmsearch_dict[prot_name] != 0\n",
    "           ):\n",
    "            file.write(f'+\\t')\n",
    "        else:\n",
    "            file.write(f' \\t')\n",
    "\n",
    "        #TeTmMPaPmX\n",
    "        if (term_hmmsearch_dict[prot_name] != 0\n",
    "            and tmp_hmmsearch_dict[prot_name] != 0\n",
    "            and mcp_hmmsearch_dict[prot_name] != 0\n",
    "            and para_hmmsearch_dict[prot_name] != 0\n",
    "            and parm_hmmsearch_dict[prot_name] != 0\n",
    "            and xerc_hmmsearch_dict[prot_name] != 0\n",
    "           ):\n",
    "            file.write(f'+\\t')\n",
    "        else:\n",
    "            file.write(f' \\t')\n",
    "            \n",
    "        #TeTmPa\n",
    "        if (term_hmmsearch_dict[prot_name] != 0\n",
    "            and tmp_hmmsearch_dict[prot_name] != 0\n",
    "            and para_hmmsearch_dict[prot_name] != 0\n",
    "           ):\n",
    "            file.write(f'+\\t')\n",
    "        else:\n",
    "            file.write(f' \\t')\n",
    "        #TeMPa\n",
    "        if (term_hmmsearch_dict[prot_name] != 0\n",
    "            and mcp_hmmsearch_dict[prot_name] != 0\n",
    "            and para_hmmsearch_dict[prot_name] != 0\n",
    "           ):\n",
    "            file.write(f'+\\n')\n",
    "        else:\n",
    "            file.write(f' \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Парсинг данных из файлов (locus_tag, protein_id, E-value_1,E-value_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_hmmsearch_pars = {}\n",
    "tmp_hmmsearch_pars = {}\n",
    "mcp_hmmsearch_pars = {}\n",
    "para_hmmsearch_pars = {}\n",
    "parm_hmmsearch_pars = {}\n",
    "xerc_hmmsearch_pars = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_E1 = 4\n",
    "N_E2 = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loop_content = (\n",
    "    (term_hmmsearch, term_hmmsearch_pars),\n",
    "    (tmp_hmmsearch, tmp_hmmsearch_pars),\n",
    "    (mcp_hmmsearch, mcp_hmmsearch_pars),\n",
    "    (para_hmmsearch, para_hmmsearch_pars),\n",
    "    (parm_hmmsearch, parm_hmmsearch_pars),\n",
    "    (xerc_hmmsearch, xerc_hmmsearch_pars)\n",
    "    \n",
    ")\n",
    "\n",
    "for prot_name in prot_names:\n",
    "    for lines, dict_prot in loop_content:\n",
    "        for line in lines:\n",
    "            try:\n",
    "                prot_name_line = line.split('_prot_')[0].split('|')[1]\n",
    "            except IndexError:\n",
    "                continue\n",
    "            \n",
    "            if prot_name == prot_name_line:\n",
    "                splt_line = line.split()\n",
    "                \n",
    "                try:\n",
    "                    protein_id = line.split('protein_id=')[1].split(']')[0]\n",
    "                except IndexError:\n",
    "                    protein_id = '-'\n",
    "                try:\n",
    "                    locus_tag = line.split('locus_tag=')[1].split(']')[0]\n",
    "                except IndexError:\n",
    "                    locus_tag = '-'\n",
    "                    \n",
    "                if prot_name in dict_prot:\n",
    "                    dict_prot[prot_name].append(\n",
    "                        (\n",
    "                            prot_name_line,\n",
    "                            locus_tag,\n",
    "                            protein_id,\n",
    "                            splt_line[N_E1],\n",
    "                            splt_line[N_E2]\n",
    "                        )\n",
    "                \n",
    "                    )\n",
    "                else:\n",
    "                     dict_prot[prot_name] = [(\n",
    "                        (\n",
    "                            prot_name_line,\n",
    "                            locus_tag,\n",
    "                            protein_id,\n",
    "                            splt_line[N_E1],\n",
    "                            splt_line[N_E2])\n",
    "                     )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "loop_content = (\n",
    "    ('term_hmmsearch_locus_tag_Evalue.out', term_hmmsearch_pars),\n",
    "    ('tmp_hmmsearch_locus_tag_Evalue.out', tmp_hmmsearch_pars),\n",
    "    ('mcp_hmmsearch_locus_tag_Evalue.out', mcp_hmmsearch_pars),\n",
    "    ('para_hmmsearch_locus_tag_Evalue.out', para_hmmsearch_pars),\n",
    "    ('parm_hmmsearch_locus_tag_Evalue.out', parm_hmmsearch_pars),\n",
    "    ('xerc_hmmsearch_locus_tag_Evalue.out', xerc_hmmsearch_pars)\n",
    "    \n",
    ")\n",
    "\n",
    "for filename, dict_prot in loop_content:\n",
    "        with open(filename, 'w') as file:\n",
    "            file.write(f'Plasmids\\tlocus_tag\\tprotein_id\\tE-value_1\\tE-value_2\\n')\n",
    "            for prot_name in prot_names:\n",
    "                try:\n",
    "                    for item in dict_prot[prot_name]:\n",
    "                        file.write(f'{item[0]}\\t{item[1]}\\t{item[2]}\\t{item[3]}\\t{item[4]}\\n')\n",
    "                except KeyError:\n",
    "                    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Формирование единого файла с результатами выборки с отсечкой по E-value_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_fill = [('-', '-', '-', '-', '-')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заполенние несуществующих ключей, для избежания KeyError в последующих элементах\n",
    "for prot_name in prot_names:\n",
    "    for name, dict_pars in loop_content:\n",
    "        try:\n",
    "            len(dict_pars[prot_name])\n",
    "        except KeyError:\n",
    "            dict_pars[prot_name] = empty_fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter E-value 1 limit: 0.001\n"
     ]
    }
   ],
   "source": [
    "treshold = float(input('Enter E-value 1 limit: '))\n",
    "with open('joinedfile_limitedEvalue.out', 'w') as file:\n",
    "    file.write(f'Plasmids\\t') # Самая первая колонка\n",
    "    file.write(f'locus_tag(Term)\\tprotein_id(Term)\\tE-value_1(Term)\\tE-value_2(Term)\\t')  # Term\n",
    "    file.write(f'locus_tag(TMP)\\tprotein_id(TMP)\\tE-value_1(TMP)\\tE-value_2(TMP)\\t')  # TMP\n",
    "    file.write(f'locus_tag(MCP)\\tprotein_id(MCP)\\tE-value_1(MCP)\\tE-value_2(MCP)\\t')  # MCP\n",
    "    file.write(f'locus_tag(ParA)\\tprotein_id(ParA)\\tE-value_1(ParA)\\tE-value_2(ParA)\\t')  # ParA\n",
    "    file.write(f'locus_tag(ParM)\\tprotein_id(ParM)\\tE-value_1(ParM)\\tE-value_2(ParM)\\t')  # ParM\n",
    "    file.write(f'locus_tag(XerC)\\tprotein_id(XerC)\\tE-value_1(XerC)\\tE-value_2(XerC)\\n')  # XerC\n",
    "    for prot_name in prot_names:\n",
    "        for i_trm, i_tmp, i_m, i_pa, i_pm, i_x in zip_longest(\n",
    "            term_hmmsearch_pars[prot_name],\n",
    "            tmp_hmmsearch_pars[prot_name],\n",
    "            mcp_hmmsearch_pars[prot_name],\n",
    "            para_hmmsearch_pars[prot_name],\n",
    "            parm_hmmsearch_pars[prot_name],\n",
    "            xerc_hmmsearch_pars[prot_name],\n",
    "            fillvalue='-----'\n",
    "        ):\n",
    "            file.write(f'{prot_name}\\t')\n",
    "            \n",
    "            dict_conds = {\n",
    "                'c_trm': False,\n",
    "                'c_tmp' : False,\n",
    "                'c_m' : False,\n",
    "                'c_pa' : False,\n",
    "                'c_pm' : False, \n",
    "                'c_x' : False\n",
    "            }\n",
    "            for key, item in [\n",
    "                ('c_trm', i_trm), ('c_tmp', i_tmp), ('c_m', i_m), \n",
    "                ('c_pa', i_pa), ('c_pm', i_pm), ('c_x', i_x)]:\n",
    "                try:\n",
    "                    dict_conds[key] = float(item[3]) <= treshold\n",
    "                except ValueError:\n",
    "                    continue\n",
    "            \n",
    "            if dict_conds['c_trm']: #(c_trm and c_tmp and c_m and c_pa and c_pm and c_x):\n",
    "                file.write(f'{i_trm[1]}\\t{i_trm[2]}\\t{i_trm[3]}\\t{i_trm[4]}\\t') # Term value\n",
    "            else:\n",
    "                file.write(f'-\\t-\\t-\\t-\\t')\n",
    "            if dict_conds['c_tmp']:\n",
    "                file.write(f'{i_tmp[1]}\\t{i_tmp[2]}\\t{i_tmp[3]}\\t{i_tmp[4]}\\t') # TMP value\n",
    "            else:\n",
    "                file.write(f'-\\t-\\t-\\t-\\t')\n",
    "            if dict_conds['c_m']:\n",
    "                file.write(f'{i_m[1]}\\t{i_m[2]}\\t{i_m[3]}\\t{i_m[4]}\\t') # MCP value\n",
    "            else:\n",
    "                file.write(f'-\\t-\\t-\\t-\\t')\n",
    "            if dict_conds['c_pa']:\n",
    "                file.write(f'{i_pa[1]}\\t{i_pa[2]}\\t{i_pa[3]}\\t{i_pa[4]}\\t') # ParA value\n",
    "            else:\n",
    "                file.write(f'-\\t-\\t-\\t-\\t')\n",
    "            if dict_conds['c_pm']:\n",
    "                file.write(f'{i_pm[1]}\\t{i_pm[2]}\\t{i_pm[3]}\\t{i_pm[4]}\\t') # ParM value\n",
    "            else:\n",
    "                file.write(f'-\\t-\\t-\\t-\\t')\n",
    "            if dict_conds['c_x']:\n",
    "                file.write(f'{i_x[1]}\\t{i_x[2]}\\t{i_x[3]}\\t{i_x[4]}\\n') # XerC value\n",
    "            else:\n",
    "                file.write(f'-\\t-\\t-\\t-\\n')\n",
    "# Сохранение файла вхождений\n",
    "with open('resultsmatch_limited_E-value_1.out', 'w') as file:\n",
    "    file.write(\n",
    "        f'Plasmids\\tTerm\\tTMP\\tMCP\\tParA\\tParM\\tXerC\\n'\n",
    "    )\n",
    "    for prot_name in prot_names:\n",
    "        file.write(f'{prot_name}\\t')\n",
    "        for filename, dict_prot in loop_content:\n",
    "            total_cond = False\n",
    "            for item in dict_prot[prot_name]:\n",
    "                try:\n",
    "                    local_cond = float(item[3]) <= treshold\n",
    "                except ValueError:\n",
    "                    continue\n",
    "                if local_cond:\n",
    "                    total_cond = True\n",
    "                else:\n",
    "                    pass\n",
    "            if total_cond:\n",
    "                file.write('+\\t')\n",
    "            else:\n",
    "                file.write('-\\t')\n",
    "        file.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выборка уникальных плазмид из таблицы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter E-value 1 limit: 0.001\n"
     ]
    }
   ],
   "source": [
    "treshold = float(input('Enter E-value 1 limit: '))\n",
    "with open('table_plasmids-phage.out', 'w') as file:\n",
    "    file.write(f'Plasmids\\tTerm\\tTMP\\tMCP\\tParA\\tParM\\tXerC\\n')\n",
    "    for prot_name in prot_names:\n",
    "                \n",
    "        unique_trm = get_unique_protein_id(term_hmmsearch_pars[prot_name], treshold)\n",
    "        unique_tmp = get_unique_protein_id(tmp_hmmsearch_pars[prot_name], treshold)\n",
    "        unique_m = get_unique_protein_id(mcp_hmmsearch_pars[prot_name], treshold)\n",
    "        unique_pa = get_unique_protein_id(para_hmmsearch_pars[prot_name], treshold)\n",
    "        unique_pm = get_unique_protein_id(parm_hmmsearch_pars[prot_name], treshold)\n",
    "        unique_x = get_unique_protein_id(xerc_hmmsearch_pars[prot_name], treshold)\n",
    "        \n",
    "        if not (unique_trm == unique_tmp == unique_m == unique_pa == unique_pm == unique_x):\n",
    "            file.write(f'{prot_name}\\t')\n",
    "            file.write(','.join(unique_trm))\n",
    "            file.write('\\t')\n",
    "            file.write(','.join(unique_tmp))\n",
    "            file.write('\\t')\n",
    "            file.write(','.join(unique_m))\n",
    "            file.write('\\t')\n",
    "            file.write(','.join(unique_pa))\n",
    "            file.write('\\t')\n",
    "            file.write(','.join(unique_pm))\n",
    "            file.write('\\t')\n",
    "            file.write(','.join(unique_x))\n",
    "            file.write('\\n')\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
